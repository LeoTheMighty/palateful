{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Palateful OCR Testing\n",
    "\n",
    "This notebook tests the HunyuanOCR model for recipe extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies if needed\n",
    "# !pip install torch transformers accelerate pillow httpx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "import httpx\n",
    "import io\n",
    "\n",
    "# Check available devices\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"MPS available: {torch.backends.mps.is_available()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"CUDA memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 1: Direct Model Usage\n",
    "\n",
    "Load and use the model directly in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoProcessor, AutoModelForVision2Seq\n",
    "\n",
    "MODEL_NAME = \"tencent/HunyuanOCR\"\n",
    "\n",
    "# Determine device\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "    dtype = torch.float16\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "    dtype = torch.float16\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "    dtype = torch.float32\n",
    "\n",
    "print(f\"Using device: {device}, dtype: {dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model and processor\n",
    "print(f\"Loading {MODEL_NAME}...\")\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(MODEL_NAME)\n",
    "model = AutoModelForVision2Seq.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    torch_dtype=dtype,\n",
    "    device_map=device if device != \"cpu\" else None,\n",
    ")\n",
    "\n",
    "if device == \"cpu\":\n",
    "    model = model.to(device)\n",
    "\n",
    "print(\"Model loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_ocr(image_path_or_url: str) -> str:\n",
    "    \"\"\"Run OCR on an image from path or URL.\"\"\"\n",
    "    # Load image\n",
    "    if image_path_or_url.startswith((\"http://\", \"https://\")):\n",
    "        response = httpx.get(image_path_or_url)\n",
    "        image = Image.open(io.BytesIO(response.content))\n",
    "    else:\n",
    "        image = Image.open(image_path_or_url)\n",
    "    \n",
    "    # Convert to RGB\n",
    "    if image.mode != \"RGB\":\n",
    "        image = image.convert(\"RGB\")\n",
    "    \n",
    "    # Prepare inputs\n",
    "    inputs = processor(images=image, return_tensors=\"pt\")\n",
    "    if device != \"cpu\":\n",
    "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    \n",
    "    # Generate\n",
    "    with torch.no_grad():\n",
    "        generated_ids = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=2048,\n",
    "            do_sample=False,\n",
    "        )\n",
    "    \n",
    "    # Decode\n",
    "    text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with a sample recipe image\n",
    "# Replace with your own image path or URL\n",
    "TEST_IMAGE = \"path/to/your/recipe/image.jpg\"  # or URL\n",
    "\n",
    "# Run OCR\n",
    "result = run_ocr(TEST_IMAGE)\n",
    "print(\"=\" * 50)\n",
    "print(\"OCR Result:\")\n",
    "print(\"=\" * 50)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 2: Using the OCR Service API\n",
    "\n",
    "If the OCR service is running, use the HTTP API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OCR_SERVICE_URL = \"http://localhost:8001\"\n",
    "\n",
    "# Check if service is running\n",
    "try:\n",
    "    response = httpx.get(f\"{OCR_SERVICE_URL}/health\")\n",
    "    print(f\"OCR Service Status: {response.json()}\")\n",
    "except Exception as e:\n",
    "    print(f\"OCR Service not running: {e}\")\n",
    "    print(\"\\nTo start the service, run:\")\n",
    "    print(\"cd services/ocr && poetry install && poetry run uvicorn src.main:app --port 8001\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ocr_via_api(image_path: str) -> dict:\n",
    "    \"\"\"Send image to OCR service and get result.\"\"\"\n",
    "    with open(image_path, \"rb\") as f:\n",
    "        files = {\"file\": (image_path, f, \"image/jpeg\")}\n",
    "        response = httpx.post(\n",
    "            f\"{OCR_SERVICE_URL}/ocr\",\n",
    "            files=files,\n",
    "            timeout=120.0,\n",
    "        )\n",
    "    response.raise_for_status()\n",
    "    return response.json()\n",
    "\n",
    "def ocr_via_api_url(image_url: str) -> dict:\n",
    "    \"\"\"Send image URL to OCR service and get result.\"\"\"\n",
    "    response = httpx.post(\n",
    "        f\"{OCR_SERVICE_URL}/ocr/url\",\n",
    "        params={\"url\": image_url},\n",
    "        timeout=120.0,\n",
    "    )\n",
    "    response.raise_for_status()\n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test via API with a local file\n",
    "# result = ocr_via_api(\"path/to/your/recipe/image.jpg\")\n",
    "# print(result[\"extracted_markdown\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown, Image as IPImage\n",
    "\n",
    "def display_result(image_path_or_url: str, ocr_text: str):\n",
    "    \"\"\"Display image and OCR result side by side.\"\"\"\n",
    "    # Display image\n",
    "    if image_path_or_url.startswith((\"http://\", \"https://\")):\n",
    "        display(IPImage(url=image_path_or_url, width=400))\n",
    "    else:\n",
    "        display(IPImage(filename=image_path_or_url, width=400))\n",
    "    \n",
    "    # Display OCR result as markdown\n",
    "    display(Markdown(\"### Extracted Text\"))\n",
    "    display(Markdown(ocr_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display your result\n",
    "# display_result(TEST_IMAGE, result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Free up GPU memory if needed\n",
    "del model\n",
    "del processor\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "print(\"Memory cleared\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
